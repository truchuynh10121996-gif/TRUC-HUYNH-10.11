"""
FastAPI Backend - H·ªá th·ªëng ƒê√°nh gi√° R·ªßi ro T√≠n d·ª•ng
Endpoints: /train, /predict, /predict-from-xlsx, /analyze, /export-report
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from dotenv import load_dotenv
import os

load_dotenv()  # T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Dict, Any, Optional, List
import pandas as pd
import os
import tempfile
from datetime import datetime
from model import credit_model
from gemini_api import get_gemini_analyzer
from excel_processor import excel_processor
from report_generator import ReportGenerator
from early_warning import early_warning_system
from anomaly_detection import anomaly_system

# Kh·ªüi t·∫°o FastAPI app
app = FastAPI(
    title="Credit Risk Assessment API",
    description="API ƒë√°nh gi√° r·ªßi ro t√≠n d·ª•ng s·ª≠ d·ª•ng Stacking Classifier",
    version="1.0.0"
)

# C·∫•u h√¨nh CORS ƒë·ªÉ frontend Vue c√≥ th·ªÉ g·ªçi API
# Development: cho ph√©p localhost:3000 (frontend Vue)
# Production: thay ƒë·ªïi origins theo domain th·∫≠t
origins = [
    "http://localhost:3000",      # Vue dev server
    "http://localhost:5173",      # Vite alternative port
    "http://127.0.0.1:3000",
    "http://127.0.0.1:5173",
    # Th√™m domain production khi deploy:
    # "https://yourdomain.com"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
)


# ================================================================================================
# PYDANTIC MODELS
# ================================================================================================

class PredictionInput(BaseModel):
    """Model cho input d·ª± b√°o (14 ch·ªâ s·ªë X1-X14)"""
    X_1: float
    X_2: float
    X_3: float
    X_4: float
    X_5: float
    X_6: float
    X_7: float
    X_8: float
    X_9: float
    X_10: float
    X_11: float
    X_12: float
    X_13: float
    X_14: float


class GeminiAPIKeyRequest(BaseModel):
    """Model cho request set Gemini API key"""
    api_key: str


# ================================================================================================
# ENDPOINTS
# ================================================================================================

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "message": "Credit Risk Assessment API",
        "version": "1.0.0",
        "status": "running"
    }


@app.post("/train")
async def train_model(file: UploadFile = File(...)):
    """
    Endpoint hu·∫•n luy·ªán m√¥ h√¨nh t·ª´ file CSV

    Args:
        file: File CSV ch·ª©a d·ªØ li·ªáu hu·∫•n luy·ªán (ph·∫£i c√≥ c·ªôt X_1 ƒë·∫øn X_14 v√† c·ªôt 'default')

    Returns:
        Dict ch·ª©a th√¥ng tin hu·∫•n luy·ªán v√† metrics
    """
    try:
        # Ki·ªÉm tra file extension
        if not file.filename.endswith('.csv'):
            raise HTTPException(status_code=400, detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng CSV")

        # L∆∞u file t·∫°m
        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        # Hu·∫•n luy·ªán m√¥ h√¨nh
        result = credit_model.train(tmp_file_path)

        # L∆∞u m√¥ h√¨nh
        credit_model.save_model("model_stacking.pkl")

        # X√≥a file t·∫°m
        os.unlink(tmp_file_path)

        return result

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh: {str(e)}")


@app.post("/predict")
async def predict(input_data: PredictionInput):
    """
    Endpoint d·ª± b√°o PD t·ª´ 14 ch·ªâ s·ªë t√†i ch√≠nh

    Args:
        input_data: Dict ch·ª©a 14 ch·ªâ s·ªë X_1 ƒë·∫øn X_14

    Returns:
        Dict ch·ª©a PD t·ª´ 4 models v√† k·∫øt qu·∫£ d·ª± ƒëo√°n
    """
    try:
        # Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c train ch∆∞a
        if credit_model.model is None:
            # Th·ª≠ load model t·ª´ file
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng upload file CSV ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc."
                )

        # Chuy·ªÉn input th√†nh DataFrame
        input_dict = input_data.dict()
        X_new = pd.DataFrame([input_dict])

        # D·ª± b√°o
        result = credit_model.predict(X_new)

        return result

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi d·ª± b√°o: {str(e)}")


@app.post("/predict-from-xlsx")
async def predict_from_xlsx(file: UploadFile = File(...)):
    """
    Endpoint d·ª± b√°o PD t·ª´ file XLSX (3 sheets: CDKT, BCTN, LCTT)
    T·ª± ƒë·ªông t√≠nh 14 ch·ªâ s·ªë v√† ch·∫°y m√¥ h√¨nh d·ª± b√°o

    Args:
        file: File XLSX ch·ª©a 3 sheets (CDKT, BCTN, LCTT)

    Returns:
        Dict ch·ª©a 14 ch·ªâ s·ªë v√† k·∫øt qu·∫£ d·ª± b√°o PD
    """
    try:
        # Ki·ªÉm tra file extension
        if not file.filename.endswith(('.xlsx', '.xls')):
            raise HTTPException(status_code=400, detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng XLSX ho·∫∑c XLS")

        # Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c train ch∆∞a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng upload file CSV ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc."
                )

        # L∆∞u file t·∫°m
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # ƒê·ªçc file XLSX
            excel_processor.read_excel(tmp_file_path)

            # T√≠nh 14 ch·ªâ s·ªë
            indicators = excel_processor.calculate_14_indicators()
            indicators_with_names = excel_processor.get_indicators_with_names()

            # Chuy·ªÉn th√†nh DataFrame ƒë·ªÉ d·ª± b√°o
            X_new = pd.DataFrame([indicators])

            # D·ª± b√°o PD
            prediction_result = credit_model.predict(X_new)

            # Tr·∫£ v·ªÅ k·∫øt qu·∫£
            return {
                "status": "success",
                "indicators": indicators_with_names,
                "indicators_dict": indicators,
                "prediction": prediction_result
            }
        finally:
            # X√≥a file t·∫°m trong finally block ƒë·ªÉ ƒë·∫£m b·∫£o file lu√¥n ƒë∆∞·ª£c x√≥a
            try:
                os.unlink(tmp_file_path)
            except Exception:
                pass  # B·ªè qua l·ªói khi x√≥a file

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi x·ª≠ l√Ω file XLSX: {str(e)}")


@app.post("/analyze")
async def analyze_with_gemini(request_data: Dict[str, Any]):
    """
    Endpoint ph√¢n t√≠ch k·∫øt qu·∫£ d·ª± b√°o b·∫±ng Gemini API

    Args:
        request_data: Dict ch·ª©a k·∫øt qu·∫£ d·ª± b√°o v√† 14 ch·ªâ s·ªë

    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ Gemini v√† khuy·∫øn ngh·ªã
    """
    try:
        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Ph√¢n t√≠ch
        analysis = analyzer.analyze_credit_risk(request_data)

        return {
            "status": "success",
            "analysis": analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ph√¢n t√≠ch b·∫±ng Gemini: {str(e)}")


@app.post("/analyze-industry")
async def analyze_industry(request_data: Dict[str, Any]):
    """
    Endpoint ph√¢n t√≠ch ng√†nh ngh·ªÅ b·∫±ng Gemini API

    Args:
        request_data: Dict ch·ª©a industry code v√† industry_name

    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch ng√†nh v√† d·ªØ li·ªáu charts
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')

        if not industry or not industry_name:
            raise HTTPException(
                status_code=400,
                detail="Thi·∫øu th√¥ng tin industry ho·∫∑c industry_name"
            )

        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Ph√¢n t√≠ch ng√†nh
        result = analyzer.analyze_industry(industry, industry_name)

        return {
            "status": "success",
            "analysis": result["analysis"],
            "charts": result.get("charts", [])
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ph√¢n t√≠ch ng√†nh: {str(e)}")


@app.post("/set-gemini-key")
async def set_gemini_key(request: GeminiAPIKeyRequest):
    """
    Endpoint ƒë·ªÉ set Gemini API key

    Args:
        request: Dict ch·ª©a api_key

    Returns:
        Dict x√°c nh·∫≠n
    """
    try:
        os.environ["GEMINI_API_KEY"] = request.api_key

        # Kh·ªüi t·∫°o l·∫°i Gemini analyzer - c·∫≠p nh·∫≠t global instance
        from gemini_api import GeminiAnalyzer
        import gemini_api
        gemini_api.gemini_analyzer = GeminiAnalyzer(request.api_key)

        return {
            "status": "success",
            "message": "Gemini API key ƒë√£ ƒë∆∞·ª£c set th√†nh c√¥ng"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi set Gemini API key: {str(e)}")


@app.post("/export-report")
async def export_report(report_data: Dict[str, Any]):
    """
    Endpoint xu·∫•t b√°o c√°o Word

    Args:
        report_data: Dict ch·ª©a prediction, indicators, v√† analysis

    Returns:
        File Word b√°o c√°o
    """
    try:
        # T·∫°o b√°o c√°o
        report_gen = ReportGenerator()
        output_path = f"bao_cao_tin_dung_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"

        report_path = report_gen.generate_report(report_data, output_path)

        # Tr·∫£ v·ªÅ file
        return FileResponse(
            path=report_path,
            media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            filename=output_path
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi xu·∫•t b√°o c√°o: {str(e)}")


@app.post("/fetch-industry-data")
async def fetch_industry_data(request_data: Dict[str, Any]):
    """
    Endpoint ƒë·ªÉ AI l·∫•y d·ªØ li·ªáu ng√†nh ngh·ªÅ t·ª± ƒë·ªông

    Args:
        request_data: Dict ch·ª©a industry code v√† industry_name

    Returns:
        Dict ch·ª©a d·ªØ li·ªáu ng√†nh ngh·ªÅ
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')

        if not industry or not industry_name:
            raise HTTPException(
                status_code=400,
                detail="Thi·∫øu th√¥ng tin industry ho·∫∑c industry_name"
            )

        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # L·∫•y d·ªØ li·ªáu
        result = analyzer.fetch_industry_data(industry, industry_name)

        return {
            "status": "success",
            "data": result.get("data", {})
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi l·∫•y d·ªØ li·ªáu ng√†nh: {str(e)}")


@app.post("/generate-charts")
async def generate_charts(request_data: Dict[str, Any]):
    """
    Endpoint t·∫°o bi·ªÉu ƒë·ªì ECharts v√† ph√¢n t√≠ch s∆° b·ªô

    Args:
        request_data: Dict ch·ª©a industry, industry_name, v√† data

    Returns:
        Dict ch·ª©a charts_data v√† brief_analysis
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')
        data = request_data.get('data', {})

        if not industry or not industry_name or not data:
            raise HTTPException(
                status_code=400,
                detail="Thi·∫øu th√¥ng tin industry, industry_name ho·∫∑c data"
            )

        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # T·∫°o bi·ªÉu ƒë·ªì v√† ph√¢n t√≠ch
        result = analyzer.generate_charts_data(industry, industry_name, data)

        return {
            "status": "success",
            "charts_data": result.get("charts_data", []),
            "brief_analysis": result.get("brief_analysis", "")
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì: {str(e)}")


@app.post("/deep-analyze-industry")
async def deep_analyze_industry_endpoint(request_data: Dict[str, Any]):
    """
    Endpoint ph√¢n t√≠ch s√¢u ·∫£nh h∆∞·ªüng c·ªßa ng√†nh ƒë·∫øn quy·∫øt ƒë·ªãnh cho vay

    Args:
        request_data: Dict ch·ª©a industry, industry_name, data, v√† brief_analysis

    Returns:
        Dict ch·ª©a deep_analysis
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')
        data = request_data.get('data', {})
        brief_analysis = request_data.get('brief_analysis', '')

        if not industry or not industry_name or not data:
            raise HTTPException(
                status_code=400,
                detail="Thi·∫øu th√¥ng tin industry, industry_name ho·∫∑c data"
            )

        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Ph√¢n t√≠ch s√¢u
        deep_analysis = analyzer.deep_analyze_industry(industry, industry_name, data, brief_analysis)

        return {
            "status": "success",
            "deep_analysis": deep_analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ph√¢n t√≠ch s√¢u: {str(e)}")


@app.post("/analyze-pd-with-industry")
async def analyze_pd_with_industry(request_data: Dict[str, Any]):
    """
    Endpoint ph√¢n t√≠ch PD k·∫øt h·ª£p v·ªõi ng√†nh ngh·ªÅ

    Args:
        request_data: Dict ch·ª©a indicators_dict, industry, v√† industry_name

    Returns:
        Dict ch·ª©a ph√¢n t√≠ch chuy√™n s√¢u v√† charts_data
    """
    try:
        indicators_dict = request_data.get('indicators_dict', {})
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')

        if not indicators_dict or not industry or not industry_name:
            raise HTTPException(
                status_code=400,
                detail="Thi·∫øu th√¥ng tin indicators_dict, industry ho·∫∑c industry_name"
            )

        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Ph√¢n t√≠ch PD k·∫øt h·ª£p
        analysis = analyzer.analyze_pd_with_industry(indicators_dict, industry, industry_name)

        # T·∫°o bi·ªÉu ƒë·ªì t·ª´ 14 ch·ªâ s·ªë
        charts_data = []

        # Bi·ªÉu ƒë·ªì 1: Radar chart cho 4 nh√≥m ch·ªâ s·ªë ch√≠nh
        charts_data.append({
            "title": {"text": "T·ªïng quan 14 Ch·ªâ s·ªë T√†i ch√≠nh", "left": "center"},
            "tooltip": {},
            "radar": {
                "indicator": [
                    {"name": "Sinh l·ªùi (X1-X4)", "max": 1},
                    {"name": "ƒê√≤n b·∫©y (X5-X6)", "max": 5},
                    {"name": "Thanh to√°n (X7-X8)", "max": 5},
                    {"name": "Hi·ªáu qu·∫£ (X9-X14)", "max": 10}
                ]
            },
            "series": [{
                "type": "radar",
                "data": [{
                    "value": [
                        (indicators_dict.get('X_1', 0) + indicators_dict.get('X_2', 0) +
                         indicators_dict.get('X_3', 0) + indicators_dict.get('X_4', 0)) / 4,
                        (indicators_dict.get('X_5', 0) + indicators_dict.get('X_6', 0)) / 2,
                        (indicators_dict.get('X_7', 0) + indicators_dict.get('X_8', 0)) / 2,
                        (indicators_dict.get('X_9', 0) + indicators_dict.get('X_10', 0) +
                         indicators_dict.get('X_11', 0) + indicators_dict.get('X_12', 0) +
                         indicators_dict.get('X_14', 0)) / 5
                    ],
                    "name": "Ch·ªâ s·ªë doanh nghi·ªáp",
                    "areaStyle": {"color": "rgba(255, 107, 157, 0.3)"}
                }]
            }]
        })

        # Bi·ªÉu ƒë·ªì 2: Bar chart so s√°nh ch·ªâ s·ªë sinh l·ªùi
        charts_data.append({
            "title": {"text": "Ch·ªâ s·ªë Sinh l·ªùi (X1-X4)", "left": "center"},
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": ["Bi√™n LN g·ªôp (X1)", "Bi√™n LN tr∆∞·ªõc thu·∫ø (X2)", "ROA (X3)", "ROE (X4)"]
            },
            "yAxis": {"type": "value"},
            "series": [{
                "data": [
                    indicators_dict.get('X_1', 0),
                    indicators_dict.get('X_2', 0),
                    indicators_dict.get('X_3', 0),
                    indicators_dict.get('X_4', 0)
                ],
                "type": "bar",
                "itemStyle": {"color": "#10B981"},
                "label": {"show": True, "position": "top", "formatter": "{c}"}
            }]
        })

        # Bi·ªÉu ƒë·ªì 3: Bar chart ch·ªâ s·ªë thanh to√°n & ƒë√≤n b·∫©y
        charts_data.append({
            "title": {"text": "Thanh to√°n & ƒê√≤n b·∫©y (X5-X8)", "left": "center"},
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": ["N·ª£/TS (X5)", "N·ª£/VCSH (X6)", "TT hi·ªán h√†nh (X7)", "TT nhanh (X8)"]
            },
            "yAxis": {"type": "value"},
            "series": [{
                "data": [
                    indicators_dict.get('X_5', 0),
                    indicators_dict.get('X_6', 0),
                    indicators_dict.get('X_7', 0),
                    indicators_dict.get('X_8', 0)
                ],
                "type": "bar",
                "itemStyle": {"color": "#3B82F6"},
                "label": {"show": True, "position": "top", "formatter": "{c}"}
            }]
        })

        # Bi·ªÉu ƒë·ªì 4: Bar chart hi·ªáu qu·∫£ ho·∫°t ƒë·ªông
        charts_data.append({
            "title": {"text": "Hi·ªáu qu·∫£ Ho·∫°t ƒë·ªông (X9-X14)", "left": "center"},
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": ["Tr·∫£ l√£i (X9)", "Tr·∫£ n·ª£ g·ªëc (X10)", "T·∫°o ti·ªÅn (X11)",
                         "V√≤ng quay HTK (X12)", "K·ª≥ thu ti·ªÅn (X13)", "Hi·ªáu su·∫•t TS (X14)"]
            },
            "yAxis": {"type": "value"},
            "series": [{
                "data": [
                    indicators_dict.get('X_9', 0),
                    indicators_dict.get('X_10', 0),
                    indicators_dict.get('X_11', 0),
                    indicators_dict.get('X_12', 0),
                    indicators_dict.get('X_13', 0),
                    indicators_dict.get('X_14', 0)
                ],
                "type": "bar",
                "itemStyle": {"color": "#9C27B0"},
                "label": {"show": True, "position": "top", "formatter": "{c}"}
            }]
        })

        return {
            "status": "success",
            "analysis": analysis,
            "charts_data": charts_data
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ph√¢n t√≠ch PD k·∫øt h·ª£p: {str(e)}")


@app.get("/model-info")
async def get_model_info():
    """
    Endpoint l·∫•y th√¥ng tin m√¥ h√¨nh hi·ªán t·∫°i

    Returns:
        Dict ch·ª©a th√¥ng tin m√¥ h√¨nh
    """
    try:
        if credit_model.model is None:
            # Th·ª≠ load model t·ª´ file
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                return {
                    "status": "not_trained",
                    "message": "M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán"
                }

        return {
            "status": "trained",
            "message": "M√¥ h√¨nh ƒë√£ s·∫µn s√†ng",
            "metrics_train": credit_model.metrics_in,
            "metrics_test": credit_model.metrics_out
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi l·∫•y th√¥ng tin m√¥ h√¨nh: {str(e)}")


@app.post("/chat-assistant")
async def chat_assistant(data: Dict[str, Any]):
    """
    Endpoint chatbot - Tr·ª£ l√Ω ·∫£o tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ ph√¢n t√≠ch

    Args:
        data: Dict ch·ª©a question, context, indicators, prediction

    Returns:
        Dict ch·ª©a answer t·ª´ Gemini
    """
    try:
        question = data.get('question', '')
        context = data.get('context', '')
        indicators = data.get('indicators', {})
        prediction = data.get('prediction', {})

        if not question:
            raise HTTPException(status_code=400, detail="Thi·∫øu c√¢u h·ªèi (question)")

        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # T·∫°o prompt cho chatbot
        prompt = f"""
B·∫°n l√† Tr·ª£ l√Ω ·∫£o chuy√™n nghi·ªáp c·ªßa Agribank, chuy√™n tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ ph√¢n t√≠ch r·ªßi ro t√≠n d·ª•ng.

**B·ªêI C·∫¢NH PH√ÇN T√çCH TR∆Ø·ªöC ƒê√ì:**
{context}

**14 CH·ªà S·ªê T√ÄI CH√çNH:**
{str(indicators)}

**K·∫æT QU·∫¢ D·ª∞ B√ÅO PD:**
{str(prediction)}

**C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:**
{question}

**Y√äU C·∫¶U TR·∫¢ L·ªúI:**
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c, d·ªÖ hi·ªÉu (100-200 t·ª´)
- D·ª±a tr√™n b·ªëi c·∫£nh ph√¢n t√≠ch v√† d·ªØ li·ªáu ƒë√£ c√≥
- N·∫øu c√¢u h·ªèi li√™n quan ƒë·∫øn ch·ªâ s·ªë t√†i ch√≠nh, gi·∫£i th√≠ch r√µ r√†ng
- N·∫øu c√¢u h·ªèi v·ªÅ khuy·∫øn ngh·ªã, ƒë∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ
- S·ª≠ d·ª•ng ti·∫øng Vi·ªát chuy√™n nghi·ªáp

H√£y tr·∫£ l·ªùi c√¢u h·ªèi:
"""

        # G·ªçi Gemini API
        response = analyzer.model.generate_content(prompt)
        answer = response.text

        return {
            "status": "success",
            "answer": answer
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}")


@app.post("/simulate-scenario")
async def simulate_scenario(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None),
    scenario_type: str = Form("mild"),
    custom_revenue: float = Form(0),
    custom_interest: float = Form(0),
    custom_cogs: float = Form(0),
    custom_liquidity: float = Form(0)
):
    """
    Endpoint m√¥ ph·ªèng k·ªãch b·∫£n x·∫•u - Stress Testing v·ªõi t√≠nh to√°n d√¢y chuy·ªÅn ho√†n ch·ªânh (Ph∆∞∆°ng √°n A)

    Args:
        file: File XLSX (n·∫øu t·∫£i file m·ªõi) - Optional
        indicators_json: JSON string ch·ª©a 14 ch·ªâ s·ªë (n·∫øu d√πng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD) - Optional
        scenario_type: Lo·∫°i k·ªãch b·∫£n ("mild", "moderate", "crisis", "custom")
        custom_revenue: % thay ƒë·ªïi doanh thu thu·∫ßn (ch·ªâ d√πng khi scenario_type="custom")
        custom_interest: % thay ƒë·ªïi l√£i su·∫•t vay (ch·ªâ d√πng khi scenario_type="custom")
        custom_cogs: % thay ƒë·ªïi gi√° v·ªën h√†ng b√°n (ch·ªâ d√πng khi scenario_type="custom")
        custom_liquidity: % s·ªëc thanh kho·∫£n TSNH (ch·ªâ d√πng khi scenario_type="custom")

    Returns:
        Dict ch·ª©a:
        - indicators_before: 14 ch·ªâ s·ªë tr∆∞·ªõc khi √°p k·ªãch b·∫£n
        - indicators_after: 14 ch·ªâ s·ªë sau khi √°p k·ªãch b·∫£n
        - prediction_before: PD tr∆∞·ªõc khi √°p k·ªãch b·∫£n
        - prediction_after: PD sau khi √°p k·ªãch b·∫£n
        - pd_change_pct: % thay ƒë·ªïi PD
        - scenario_info: Th√¥ng tin v·ªÅ k·ªãch b·∫£n ƒë√£ √°p d·ª•ng
    """
    try:
        import json

        # Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c train ch∆∞a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng upload file CSV ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc."
                )

        # 1. L·∫§Y 14 CH·ªà S·ªê BAN ƒê·∫¶U (indicators_before)
        indicators_before = {}

        if file:
            # Tr∆∞·ªùng h·ª£p 1: T·∫£i file XLSX m·ªõi
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng XLSX ho·∫∑c XLS")

            # L∆∞u file t·∫°m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # ƒê·ªçc file XLSX v√† t√≠nh 14 ch·ªâ s·ªë
                excel_processor.read_excel(tmp_file_path)
                indicators_before = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # Tr∆∞·ªùng h·ª£p 2: S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD
            indicators_before = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui l√≤ng cung c·∫•p file XLSX ho·∫∑c d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD"
            )

        # 2. X√ÅC ƒê·ªäNH % BI·∫æN ƒê·ªòNG THEO K·ªäCH B·∫¢N (PH∆Ø∆†NG √ÅN A - STRESS TESTING)
        scenario_configs = {
            "mild": {
                "name": "üü† Kinh t·∫ø gi·∫£m nh·∫π",
                "revenue_change": -5,
                "interest_rate_change": 10,
                "cogs_change": 3,
                "liquidity_shock": -5
            },
            "moderate": {
                "name": "üî¥ C√∫ s·ªëc kinh t·∫ø trung b√¨nh",
                "revenue_change": -12,
                "interest_rate_change": 25,
                "cogs_change": 8,
                "liquidity_shock": -12
            },
            "crisis": {
                "name": "‚ö´ Kh·ªßng ho·∫£ng",
                "revenue_change": -25,
                "interest_rate_change": 40,
                "cogs_change": 15,
                "liquidity_shock": -25
            },
            "custom": {
                "name": "üü° T√πy ch·ªçn bi·∫øn ƒë·ªông",
                "revenue_change": custom_revenue,
                "interest_rate_change": custom_interest,
                "cogs_change": custom_cogs,
                "liquidity_shock": custom_liquidity
            }
        }

        if scenario_type not in scenario_configs:
            raise HTTPException(
                status_code=400,
                detail=f"Lo·∫°i k·ªãch b·∫£n kh√¥ng h·ª£p l·ªá. Ch·ªçn: {', '.join(scenario_configs.keys())}"
            )

        scenario = scenario_configs[scenario_type]

        # 3. T√çNH 14 CH·ªà S·ªê SAU KHI √ÅP K·ªäCH B·∫¢N (indicators_after)
        # S·ª≠ d·ª•ng PH∆Ø∆†NG √ÅN A: Stress Testing v·ªõi t√≠nh to√°n d√¢y chuy·ªÅn ho√†n ch·ªânh
        indicators_after = excel_processor.simulate_scenario_full_propagation(
            original_indicators=indicators_before,
            revenue_change_pct=scenario["revenue_change"],
            interest_rate_change_pct=scenario["interest_rate_change"],
            cogs_change_pct=scenario["cogs_change"],
            liquidity_shock_pct=scenario["liquidity_shock"]
        )

        # 4. D·ª∞ B√ÅO PD TR∆Ø·ªöC V√Ä SAU
        # D·ª± b√°o PD tr∆∞·ªõc khi √°p k·ªãch b·∫£n
        X_before = pd.DataFrame([indicators_before])
        prediction_before = credit_model.predict(X_before)

        # D·ª± b√°o PD sau khi √°p k·ªãch b·∫£n
        X_after = pd.DataFrame([indicators_after])
        prediction_after = credit_model.predict(X_after)

        # 5. T√çNH % THAY ƒê·ªîI PD
        pd_before = prediction_before["pd_stacking"]
        pd_after = prediction_after["pd_stacking"]
        pd_change_pct = ((pd_after - pd_before) / pd_before * 100) if pd_before != 0 else 0

        # 6. CHU·∫®N B·ªä K·∫æT QU·∫¢ TR·∫¢ V·ªÄ
        # Chuy·ªÉn ƒë·ªïi indicators th√†nh list c√≥ t√™n
        def indicators_to_list(indicators_dict):
            indicator_names = {
                'X_1': 'H·ªá s·ªë bi√™n l·ª£i nhu·∫≠n g·ªôp',
                'X_2': 'H·ªá s·ªë bi√™n l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø',
                'X_3': 'T·ª∑ su·∫•t l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø tr√™n t·ªïng t√†i s·∫£n (ROA)',
                'X_4': 'T·ª∑ su·∫•t l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø tr√™n v·ªën ch·ªß s·ªü h·ªØu (ROE)',
                'X_5': 'H·ªá s·ªë n·ª£ tr√™n t√†i s·∫£n',
                'X_6': 'H·ªá s·ªë n·ª£ tr√™n v·ªën ch·ªß s·ªü h·ªØu',
                'X_7': 'Kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh',
                'X_8': 'Kh·∫£ nƒÉng thanh to√°n nhanh',
                'X_9': 'H·ªá s·ªë kh·∫£ nƒÉng tr·∫£ l√£i',
                'X_10': 'H·ªá s·ªë kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc',
                'X_11': 'H·ªá s·ªë kh·∫£ nƒÉng t·∫°o ti·ªÅn tr√™n v·ªën ch·ªß s·ªü h·ªØu',
                'X_12': 'V√≤ng quay h√†ng t·ªìn kho',
                'X_13': 'K·ª≥ thu ti·ªÅn b√¨nh qu√¢n',
                'X_14': 'Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n'
            }
            result = []
            for key, value in indicators_dict.items():
                result.append({
                    'code': key,
                    'name': indicator_names[key],
                    'value': value
                })
            return result

        return {
            "status": "success",
            "scenario_info": {
                "type": scenario_type,
                "name": scenario["name"],
                "changes": {
                    "revenue": scenario["revenue_change"],
                    "interest": scenario["interest_rate_change"],
                    "cogs": scenario["cogs_change"],
                    "liquidity": scenario["liquidity_shock"]
                }
            },
            "indicators_before": indicators_to_list(indicators_before),
            "indicators_before_dict": indicators_before,
            "indicators_after": indicators_to_list(indicators_after),
            "indicators_after_dict": indicators_after,
            "prediction_before": prediction_before,
            "prediction_after": prediction_after,
            "pd_change": {
                "before": pd_before,
                "after": pd_after,
                "change_pct": round(pd_change_pct, 2),
                "change_absolute": round(pd_after - pd_before, 6)
            }
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi m√¥ ph·ªèng k·ªãch b·∫£n: {str(e)}")


@app.post("/analyze-scenario")
async def analyze_scenario(request_data: Dict[str, Any]):
    """
    Endpoint ph√¢n t√≠ch k·∫øt qu·∫£ m√¥ ph·ªèng k·ªãch b·∫£n b·∫±ng Gemini API

    Args:
        request_data: Dict ch·ª©a k·∫øt qu·∫£ m√¥ ph·ªèng k·ªãch b·∫£n

    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ Gemini
    """
    try:
        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Ph√¢n t√≠ch k·ªãch b·∫£n
        analysis = analyzer.analyze_scenario_simulation(request_data)

        return {
            "status": "success",
            "analysis": analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ph√¢n t√≠ch k·ªãch b·∫£n b·∫±ng Gemini: {str(e)}")


@app.post("/simulate-scenario-macro")
async def simulate_scenario_macro(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None),
    scenario_type: str = Form("recession_mild"),
    industry_code: str = Form("manufacturing"),
    custom_gdp: float = Form(0),
    custom_cpi: float = Form(0),
    custom_ppi: float = Form(0),
    custom_policy_rate: float = Form(0),
    custom_fx: float = Form(0)
):
    """
    Endpoint m√¥ ph·ªèng k·ªãch b·∫£n vƒ© m√¥ (Macro Stress Testing)

    Args:
        file: File XLSX (n·∫øu t·∫£i file m·ªõi) - Optional
        indicators_json: JSON string ch·ª©a 14 ch·ªâ s·ªë (n·∫øu d√πng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD) - Optional
        scenario_type: Lo·∫°i k·ªãch b·∫£n ("recession_mild", "recession_moderate", "crisis", "custom")
        industry_code: M√£ ng√†nh ("manufacturing", "export", "retail")
        custom_gdp: % tƒÉng tr∆∞·ªüng GDP (ch·ªâ d√πng khi scenario_type="custom")
        custom_cpi: % l·∫°m ph√°t CPI (ch·ªâ d√πng khi scenario_type="custom")
        custom_ppi: % l·∫°m ph√°t PPI (ch·ªâ d√πng khi scenario_type="custom")
        custom_policy_rate: Thay ƒë·ªïi l√£i su·∫•t NHNN bps (ch·ªâ d√πng khi scenario_type="custom")
        custom_fx: % thay ƒë·ªïi t·ª∑ gi√° USD/VND (ch·ªâ d√πng khi scenario_type="custom")

    Returns:
        Dict ch·ª©a:
        - macro_variables: 5 bi·∫øn vƒ© m√¥ ƒë√£ ch·ªçn
        - micro_shocks: 4 bi·∫øn vi m√¥ ƒë∆∞·ª£c t√≠nh t·ª´ k√™nh truy·ªÅn d·∫´n
        - indicators_before: 14 ch·ªâ s·ªë tr∆∞·ªõc khi √°p k·ªãch b·∫£n
        - indicators_after: 14 ch·ªâ s·ªë sau khi √°p k·ªãch b·∫£n
        - prediction_before: PD tr∆∞·ªõc khi √°p k·ªãch b·∫£n
        - prediction_after: PD sau khi √°p k·ªãch b·∫£n
        - pd_change_pct: % thay ƒë·ªïi PD
        - scenario_info: Th√¥ng tin v·ªÅ k·ªãch b·∫£n ƒë√£ √°p d·ª•ng
    """
    try:
        import json

        # Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c train ch∆∞a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng upload file CSV ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc."
                )

        # 1. L·∫§Y 14 CH·ªà S·ªê BAN ƒê·∫¶U (indicators_before)
        indicators_before = {}

        if file:
            # Tr∆∞·ªùng h·ª£p 1: T·∫£i file XLSX m·ªõi
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng XLSX ho·∫∑c XLS")

            # L∆∞u file t·∫°m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # ƒê·ªçc file XLSX v√† t√≠nh 14 ch·ªâ s·ªë
                excel_processor.read_excel(tmp_file_path)
                indicators_before = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # Tr∆∞·ªùng h·ª£p 2: S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD
            indicators_before = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui l√≤ng cung c·∫•p file XLSX ho·∫∑c d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD"
            )

        # 2. X√ÅC ƒê·ªäNH 5 BI·∫æN Vƒ® M√î THEO K·ªäCH B·∫¢N
        macro_scenario_configs = {
            "recession_mild": {
                "name": "üü† Suy tho√°i nh·∫π",
                "gdp_growth_pct": -1.5,
                "inflation_cpi_pct": 6.0,
                "inflation_ppi_pct": 8.0,
                "policy_rate_change_bps": 100,
                "fx_usd_vnd_pct": 3.0
            },
            "recession_moderate": {
                "name": "üî¥ Suy tho√°i trung b√¨nh",
                "gdp_growth_pct": -3.5,
                "inflation_cpi_pct": 10.0,
                "inflation_ppi_pct": 14.0,
                "policy_rate_change_bps": 200,
                "fx_usd_vnd_pct": 6.0
            },
            "crisis": {
                "name": "‚ö´ Kh·ªßng ho·∫£ng",
                "gdp_growth_pct": -6.0,
                "inflation_cpi_pct": 15.0,
                "inflation_ppi_pct": 20.0,
                "policy_rate_change_bps": 300,
                "fx_usd_vnd_pct": 10.0
            },
            "custom": {
                "name": "üü° T√πy ch·ªânh vƒ© m√¥",
                "gdp_growth_pct": custom_gdp,
                "inflation_cpi_pct": custom_cpi,
                "inflation_ppi_pct": custom_ppi,
                "policy_rate_change_bps": custom_policy_rate,
                "fx_usd_vnd_pct": custom_fx
            }
        }

        if scenario_type not in macro_scenario_configs:
            raise HTTPException(
                status_code=400,
                detail=f"Lo·∫°i k·ªãch b·∫£n kh√¥ng h·ª£p l·ªá. Ch·ªçn: {', '.join(macro_scenario_configs.keys())}"
            )

        macro_scenario = macro_scenario_configs[scenario_type]

        # 3. K√äNH TRUY·ªÄN D·∫™N: MACRO ‚Üí MICRO
        # G·ªçi function macro_to_micro_transmission()
        micro_shocks = excel_processor.macro_to_micro_transmission(
            gdp_growth_pct=macro_scenario["gdp_growth_pct"],
            inflation_cpi_pct=macro_scenario["inflation_cpi_pct"],
            inflation_ppi_pct=macro_scenario["inflation_ppi_pct"],
            policy_rate_change_bps=macro_scenario["policy_rate_change_bps"],
            fx_usd_vnd_pct=macro_scenario["fx_usd_vnd_pct"],
            industry_code=industry_code
        )

        # 4. T√çNH 14 CH·ªà S·ªê SAU KHI √ÅP 4 BI·∫æN VI M√î
        # S·ª≠ d·ª•ng simulate_scenario_full_propagation() v·ªõi 4 bi·∫øn vi m√¥
        indicators_after = excel_processor.simulate_scenario_full_propagation(
            original_indicators=indicators_before,
            revenue_change_pct=micro_shocks["revenue_change_pct"],
            interest_rate_change_pct=micro_shocks["interest_rate_change_pct"],
            cogs_change_pct=micro_shocks["cogs_change_pct"],
            liquidity_shock_pct=micro_shocks["liquidity_shock_pct"]
        )

        # 5. D·ª∞ B√ÅO PD TR∆Ø·ªöC V√Ä SAU
        # D·ª± b√°o PD tr∆∞·ªõc khi √°p k·ªãch b·∫£n
        X_before = pd.DataFrame([indicators_before])
        prediction_before = credit_model.predict(X_before)

        # D·ª± b√°o PD sau khi √°p k·ªãch b·∫£n
        X_after = pd.DataFrame([indicators_after])
        prediction_after = credit_model.predict(X_after)

        # 6. T√çNH % THAY ƒê·ªîI PD
        pd_before = prediction_before["pd_stacking"]
        pd_after = prediction_after["pd_stacking"]
        pd_change_pct = ((pd_after - pd_before) / pd_before * 100) if pd_before != 0 else 0

        # 7. CHU·∫®N B·ªä K·∫æT QU·∫¢ TR·∫¢ V·ªÄ
        # Chuy·ªÉn ƒë·ªïi indicators th√†nh list c√≥ t√™n
        def indicators_to_list(indicators_dict):
            indicator_names = {
                'X_1': 'H·ªá s·ªë bi√™n l·ª£i nhu·∫≠n g·ªôp',
                'X_2': 'H·ªá s·ªë bi√™n l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø',
                'X_3': 'T·ª∑ su·∫•t l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø tr√™n t·ªïng t√†i s·∫£n (ROA)',
                'X_4': 'T·ª∑ su·∫•t l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø tr√™n v·ªën ch·ªß s·ªü h·ªØu (ROE)',
                'X_5': 'H·ªá s·ªë n·ª£ tr√™n t√†i s·∫£n',
                'X_6': 'H·ªá s·ªë n·ª£ tr√™n v·ªën ch·ªß s·ªü h·ªØu',
                'X_7': 'Kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh',
                'X_8': 'Kh·∫£ nƒÉng thanh to√°n nhanh',
                'X_9': 'H·ªá s·ªë kh·∫£ nƒÉng tr·∫£ l√£i',
                'X_10': 'H·ªá s·ªë kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc',
                'X_11': 'H·ªá s·ªë kh·∫£ nƒÉng t·∫°o ti·ªÅn tr√™n v·ªën ch·ªß s·ªü h·ªØu',
                'X_12': 'V√≤ng quay h√†ng t·ªìn kho',
                'X_13': 'K·ª≥ thu ti·ªÅn b√¨nh qu√¢n',
                'X_14': 'Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n'
            }
            result = []
            for key, value in indicators_dict.items():
                result.append({
                    'code': key,
                    'name': indicator_names[key],
                    'value': value
                })
            return result

        # T√™n ng√†nh ngh·ªÅ
        industry_names = {
            "manufacturing": "S·∫£n xu·∫•t",
            "export": "Xu·∫•t kh·∫©u",
            "retail": "B√°n l·∫ª"
        }

        return {
            "status": "success",
            "scenario_info": {
                "type": scenario_type,
                "name": macro_scenario["name"],
                "industry": industry_names.get(industry_code, industry_code)
            },
            "macro_variables": {
                "gdp_growth_pct": macro_scenario["gdp_growth_pct"],
                "inflation_cpi_pct": macro_scenario["inflation_cpi_pct"],
                "inflation_ppi_pct": macro_scenario["inflation_ppi_pct"],
                "policy_rate_change_bps": macro_scenario["policy_rate_change_bps"],
                "fx_usd_vnd_pct": macro_scenario["fx_usd_vnd_pct"]
            },
            "micro_shocks": micro_shocks,
            "indicators_before": indicators_to_list(indicators_before),
            "indicators_before_dict": indicators_before,
            "indicators_after": indicators_to_list(indicators_after),
            "indicators_after_dict": indicators_after,
            "prediction_before": prediction_before,
            "prediction_after": prediction_after,
            "pd_change": {
                "before": pd_before,
                "after": pd_after,
                "change_pct": round(pd_change_pct, 2),
                "change_absolute": round(pd_after - pd_before, 6)
            }
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi m√¥ ph·ªèng k·ªãch b·∫£n vƒ© m√¥: {str(e)}")


@app.post("/analyze-macro")
async def analyze_macro(request_data: Dict[str, Any]):
    """
    Endpoint ph√¢n t√≠ch k·∫øt qu·∫£ m√¥ ph·ªèng vƒ© m√¥ b·∫±ng Gemini API

    Args:
        request_data: Dict ch·ª©a k·∫øt qu·∫£ m√¥ ph·ªèng vƒ© m√¥

    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ Gemini
    """
    try:
        # L·∫•y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # L·∫•y th√¥ng tin t·ª´ request
        scenario_info = request_data.get('scenario_info', {})
        macro_variables = request_data.get('macro_variables', {})
        micro_shocks = request_data.get('micro_shocks', {})
        indicators_before = request_data.get('indicators_before_dict', {})
        indicators_after = request_data.get('indicators_after_dict', {})
        pd_change = request_data.get('pd_change', {})

        # T·∫°o prompt cho Gemini
        prompt = f"""
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch kinh t·∫ø vƒ© m√¥ v√† r·ªßi ro t√≠n d·ª•ng c·ªßa Agribank. H√£y ph√¢n t√≠ch k·∫øt qu·∫£ m√¥ ph·ªèng k·ªãch b·∫£n vƒ© m√¥ d∆∞·ªõi ƒë√¢y.

**TH√îNG TIN K·ªäCH B·∫¢N Vƒ® M√î:**

**K·ªãch b·∫£n:** {scenario_info.get('name', 'N/A')}
**Ng√†nh:** {scenario_info.get('industry', 'N/A')}

**5 BI·∫æN Vƒ® M√î:**
- TƒÉng tr∆∞·ªüng GDP: {macro_variables.get('gdp_growth_pct', 0):.1f}%
- L·∫°m ph√°t CPI: {macro_variables.get('inflation_cpi_pct', 0):.1f}%
- L·∫°m ph√°t PPI: {macro_variables.get('inflation_ppi_pct', 0):.1f}%
- Thay ƒë·ªïi l√£i su·∫•t NHNN: {macro_variables.get('policy_rate_change_bps', 0):.0f} bps
- Thay ƒë·ªïi t·ª∑ gi√° USD/VND: {macro_variables.get('fx_usd_vnd_pct', 0):.1f}%

**4 BI·∫æN VI M√î (K√™nh truy·ªÅn d·∫´n):**
- Thay ƒë·ªïi doanh thu: {micro_shocks.get('revenue_change_pct', 0):.2f}%
- Thay ƒë·ªïi l√£i su·∫•t vay: {micro_shocks.get('interest_rate_change_pct', 0):.2f}%
- Thay ƒë·ªïi gi√° v·ªën h√†ng b√°n: {micro_shocks.get('cogs_change_pct', 0):.2f}%
- S·ªëc thanh kho·∫£n: {micro_shocks.get('liquidity_shock_pct', 0):.2f}%

**T√ÅC ƒê·ªòNG ƒê·∫æN X√ÅC SU·∫§T V·ª† N·ª¢:**
- PD tr∆∞·ªõc: {pd_change.get('before', 0):.4f}
- PD sau: {pd_change.get('after', 0):.4f}
- Thay ƒë·ªïi: {pd_change.get('change_pct', 0):.2f}% (tuy·ªát ƒë·ªëi: {pd_change.get('change_absolute', 0):.4f})

**Y√äU C·∫¶U PH√ÇN T√çCH:**

H√£y vi·∫øt b√°o c√°o ph√¢n t√≠ch chi ti·∫øt (s·ª≠ d·ª•ng Markdown) v·ªõi c·∫•u tr√∫c sau:

## üìä T·ªîNG QUAN K·ªäCH B·∫¢N Vƒ® M√î
(2-3 c√¢u m√¥ t·∫£ k·ªãch b·∫£n vƒ© m√¥ v√† m·ª©c ƒë·ªô nghi√™m tr·ªçng)

## üîÑ PH√ÇN T√çCH K√äNH TRUY·ªÄN D·∫™N
(Gi·∫£i th√≠ch c√°ch 5 bi·∫øn vƒ© m√¥ t√°c ƒë·ªông l√™n 4 bi·∫øn vi m√¥ c·ªßa doanh nghi·ªáp)

### T√°c ƒë·ªông l√™n Doanh thu
(Ph√¢n t√≠ch chi ti·∫øt)

### T√°c ƒë·ªông l√™n Chi ph√≠ & L√£i su·∫•t
(Ph√¢n t√≠ch chi ti·∫øt)

### T√°c ƒë·ªông l√™n Thanh kho·∫£n
(Ph√¢n t√≠ch chi ti·∫øt)

## üìà ƒê√ÅNH GI√Å T√ÅC ƒê·ªòNG ƒê·∫æN PD

### M·ª©c ƒë·ªô thay ƒë·ªïi
(Ph√¢n t√≠ch m·ª©c ƒë·ªô thay ƒë·ªïi PD: nh·∫π/trung b√¨nh/nghi√™m tr·ªçng)

### C√°c ch·ªâ s·ªë t√†i ch√≠nh ch·ªãu ·∫£nh h∆∞·ªüng nhi·ªÅu nh·∫•t
(Li·ªát k√™ 3-5 ch·ªâ s·ªë b·ªã ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t)

## üí° KHUY·∫æN NGH·ªä

### ƒê·ªëi v·ªõi Doanh nghi·ªáp
(2-3 khuy·∫øn ngh·ªã c·ª• th·ªÉ)

### ƒê·ªëi v·ªõi Ng√¢n h√†ng
(2-3 khuy·∫øn ngh·ªã v·ªÅ ch√≠nh s√°ch t√≠n d·ª•ng)

## ‚ö†Ô∏è R·ª¶I RO C·∫¶N L∆ØU √ù
(Li·ªát k√™ 2-3 r·ªßi ro ti·ªÅm ·∫©n c·∫ßn theo d√µi)

---
**L∆∞u √Ω:** Vi·∫øt ng·∫Øn g·ªçn, chuy√™n nghi·ªáp, d·ªÖ hi·ªÉu. T·∫≠p trung v√†o insights v√† actionable recommendations.
"""

        # G·ªçi Gemini API
        response = analyzer.model.generate_content(prompt)
        analysis = response.text

        return {
            "status": "success",
            "analysis": analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng set bi·∫øn m√¥i tr∆∞·ªùng. Chi ti·∫øt: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ph√¢n t√≠ch vƒ© m√¥ b·∫±ng Gemini: {str(e)}")


@app.post("/train-early-warning-model")
async def train_early_warning_model(file: UploadFile = File(...)):
    """
    Endpoint hu·∫•n luy·ªán Early Warning System

    Args:
        file: File Excel ch·ª©a 1300 DN v·ªõi 14 ch·ªâ s·ªë (X_1 ‚Üí X_14) + c·ªôt 'label' (0=kh√¥ng v·ª° n·ª£, 1=v·ª° n·ª£)

    Returns:
        Dict ch·ª©a th√¥ng tin v·ªÅ training:
        - status: success
        - num_samples: S·ªë l∆∞·ª£ng m·∫´u
        - feature_importances: Feature importances t·ª´ RandomForest
        - cluster_distribution: Ph√¢n b·ªë c√°c cluster
    """
    try:
        # Ki·ªÉm tra file extension
        if not file.filename.endswith(('.xlsx', '.xls', '.csv')):
            raise HTTPException(
                status_code=400,
                detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng XLSX, XLS ho·∫∑c CSV"
            )

        # L∆∞u file t·∫°m
        suffix = '.xlsx' if file.filename.endswith(('.xlsx', '.xls')) else '.csv'
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # ƒê·ªçc file
            if suffix == '.csv':
                df = pd.read_csv(tmp_file_path)
            else:
                df = pd.read_excel(tmp_file_path)

            # Ki·ªÉm tra c√°c c·ªôt c·∫ßn thi·∫øt
            required_cols = [f'X_{i}' for i in range(1, 15)] + ['label']
            missing_cols = [col for col in required_cols if col not in df.columns]

            if missing_cols:
                raise HTTPException(
                    status_code=400,
                    detail=f"File thi·∫øu c√°c c·ªôt: {', '.join(missing_cols)}"
                )

            # Train Early Warning System
            result = early_warning_system.train_models(df)

            return {
                "status": "success",
                "message": "Early Warning System trained successfully!",
                **result
            }

        finally:
            # X√≥a file t·∫°m
            try:
                os.unlink(tmp_file_path)
            except Exception:
                pass

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi train Early Warning System: {str(e)}")


@app.post("/early-warning-check")
async def early_warning_check(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None),
    report_period: Optional[str] = Form(None),
    industry_code: str = Form("manufacturing")
):
    """
    Endpoint ki·ªÉm tra c·∫£nh b√°o r·ªßi ro s·ªõm

    Args:
        file: File Excel (n·∫øu t·∫£i file m·ªõi) - Optional
        indicators_json: JSON string ch·ª©a 14 ch·ªâ s·ªë (n·∫øu d√πng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD) - Optional
        report_period: K·ª≥ b√°o c√°o (Qu√Ω/6 th√°ng/NƒÉm) - Optional, ch·ªâ ƒë·ªÉ hi·ªÉn th·ªã
        industry_code: M√£ ng√†nh ("manufacturing", "export", "retail")

    Returns:
        Dict ch·ª©a:
        - health_score: Health Score (0-100)
        - risk_level: M·ª©c r·ªßi ro (Safe/Watch/Warning/Alert)
        - risk_level_color: M√†u s·∫Øc
        - current_pd: PD hi·ªán t·∫°i
        - top_weaknesses: Top 3 ƒëi·ªÉm y·∫øu
        - cluster_info: Th√¥ng tin cluster
        - pd_projection: D·ª± b√°o PD t∆∞∆°ng lai
        - gemini_diagnosis: B√°o c√°o ch·∫©n ƒëo√°n t·ª´ Gemini AI
        - feature_importances: Feature importances
    """
    try:
        import json

        # Ki·ªÉm tra Early Warning System ƒë√£ ƒë∆∞·ª£c train ch∆∞a
        if early_warning_system.stacking_model is None:
            raise HTTPException(
                status_code=400,
                detail="Early Warning System ch∆∞a ƒë∆∞·ª£c train. Vui l√≤ng upload file training data tr∆∞·ªõc."
            )

        # Ki·ªÉm tra m√¥ h√¨nh PD ƒë√£ ƒë∆∞·ª£c train ch∆∞a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="M√¥ h√¨nh PD ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng train m√¥ h√¨nh tr∆∞·ªõc."
                )

        # 1. L·∫§Y 14 CH·ªà S·ªê
        indicators = {}

        if file:
            # Tr∆∞·ªùng h·ª£p 1: T·∫£i file XLSX m·ªõi
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng XLSX ho·∫∑c XLS")

            # L∆∞u file t·∫°m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # ƒê·ªçc file XLSX v√† t√≠nh 14 ch·ªâ s·ªë
                excel_processor.read_excel(tmp_file_path)
                indicators = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # Tr∆∞·ªùng h·ª£p 2: S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD
            indicators = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui l√≤ng cung c·∫•p file XLSX ho·∫∑c d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD"
            )

        # 2. T√çNH HEALTH SCORE
        health_score = early_warning_system.calculate_health_score(indicators)

        # 3. PH√ÇN LO·∫†I M·ª®C R·ª¶I RO
        risk_info = early_warning_system.classify_risk_level(health_score)

        # 4. T√çNH PD HI·ªÜN T·∫†I (s·ª≠ d·ª•ng early_warning_system.stacking_model)
        feature_cols = [f'X_{i}' for i in range(1, 15)]
        X_current = [[indicators[col] for col in feature_cols]]
        current_pd = early_warning_system.stacking_model.predict_proba(X_current)[0, 1] * 100

        # 5. PH√ÅT HI·ªÜN ƒêI·ªÇM Y·∫æU
        weaknesses = early_warning_system.detect_weaknesses(indicators)

        # 6. X√ÅC ƒê·ªäNH V·ªä TR√ç CLUSTER
        cluster_info = early_warning_system.get_cluster_position(indicators)

        # 7. D·ª∞ B√ÅO PD T∆Ø∆†NG LAI (3/6/12 th√°ng x 3 k·ªãch b·∫£n)
        scenarios = ['recession_mild', 'recession_moderate', 'crisis']
        time_periods = [3, 6, 12]

        pd_projection = {
            'current': current_pd
        }

        for scenario in scenarios:
            pd_projection[scenario] = {}
            for months in time_periods:
                pd_future = early_warning_system.project_future_pd(
                    indicators=indicators,
                    months=months,
                    scenario=scenario,
                    excel_processor=excel_processor,
                    industry_code=industry_code
                )
                pd_projection[scenario][f'{months}_months'] = pd_future

        # 8. T·∫†O B√ÅO C√ÅO CH·∫®N ƒêO√ÅN B·∫∞NG GEMINI AI
        gemini_diagnosis = early_warning_system.generate_gemini_diagnosis(
            health_score=health_score,
            risk_info=risk_info,
            weaknesses=weaknesses,
            cluster_info=cluster_info,
            pd_projections=pd_projection,
            current_pd=current_pd,
            gemini_api_key=GEMINI_API_KEY
        )

        # 9. TR·∫¢ V·ªÄ K·∫æT QU·∫¢
        return {
            "status": "success",
            "health_score": health_score,
            "risk_level": risk_info['risk_level'],
            "risk_level_color": risk_info['risk_level_color'],
            "risk_level_icon": risk_info['risk_level_icon'],
            "risk_level_text": risk_info['risk_level_text'],
            "current_pd": current_pd,
            "top_weaknesses": weaknesses,
            "cluster_info": cluster_info,
            "pd_projection": pd_projection,
            "gemini_diagnosis": gemini_diagnosis,
            "feature_importances": early_warning_system.feature_importances,
            "report_period": report_period
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ki·ªÉm tra c·∫£nh b√°o r·ªßi ro: {str(e)}")


@app.post("/train-anomaly-model")
async def train_anomaly_model(file: UploadFile = File(...)):
    """
    Endpoint hu·∫•n luy·ªán Anomaly Detection System

    Args:
        file: File Excel/CSV ch·ª©a 1300 DN v·ªõi 14 ch·ªâ s·ªë (X_1 ‚Üí X_14) + c·ªôt 'label' (0=kh·ªèe m·∫°nh, 1=v·ª° n·ª£)

    Returns:
        Dict ch·ª©a th√¥ng tin v·ªÅ training:
        - status: success
        - feature_statistics: Th·ªëng k√™ 14 features (P5, P25, P50, P75, P95)
        - contamination_rate: T·ª∑ l·ªá contamination
    """
    try:
        # Ki·ªÉm tra file extension
        if not file.filename.endswith(('.xlsx', '.xls', '.csv')):
            raise HTTPException(
                status_code=400,
                detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng XLSX, XLS ho·∫∑c CSV"
            )

        # L∆∞u file t·∫°m
        suffix = '.xlsx' if file.filename.endswith(('.xlsx', '.xls')) else '.csv'
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # ƒê·ªçc file
            if suffix == '.csv':
                df = pd.read_csv(tmp_file_path)
            else:
                df = pd.read_excel(tmp_file_path)

            # Ki·ªÉm tra c√°c c·ªôt c·∫ßn thi·∫øt
            required_cols = [f'X_{i}' for i in range(1, 15)] + ['label']
            missing_cols = [col for col in required_cols if col not in df.columns]

            if missing_cols:
                raise HTTPException(
                    status_code=400,
                    detail=f"File thi·∫øu c√°c c·ªôt: {', '.join(missing_cols)}"
                )

            # Train Anomaly Detection System
            result = anomaly_system.train_model(df)

            return {
                "status": "success",
                "message": "Anomaly Detection System trained successfully!",
                **result
            }

        finally:
            # X√≥a file t·∫°m
            try:
                os.unlink(tmp_file_path)
            except Exception:
                pass

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi train Anomaly Detection System: {str(e)}")


@app.post("/check-anomaly")
async def check_anomaly(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None)
):
    """
    Endpoint ki·ªÉm tra b·∫•t th∆∞·ªùng cho DN m·ªõi

    Args:
        file: File Excel (n·∫øu t·∫£i file m·ªõi) - Optional
        indicators_json: JSON string ch·ª©a 14 ch·ªâ s·ªë (n·∫øu d√πng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD) - Optional

    Returns:
        Dict ch·ª©a:
        - anomaly_score: ƒêi·ªÉm b·∫•t th∆∞·ªùng (0-100)
        - risk_level: M·ª©c r·ªßi ro
        - abnormal_features: List c√°c features b·∫•t th∆∞·ªùng
        - anomaly_type: Lo·∫°i b·∫•t th∆∞·ªùng
        - gemini_explanation: Gi·∫£i th√≠ch t·ª´ Gemini AI
        - comparison_with_healthy: So s√°nh v·ªõi DN kh·ªèe m·∫°nh
    """
    try:
        import json

        # Ki·ªÉm tra Anomaly Detection System ƒë√£ ƒë∆∞·ª£c train ch∆∞a
        if anomaly_system.model is None:
            raise HTTPException(
                status_code=400,
                detail="Anomaly Detection System ch∆∞a ƒë∆∞·ª£c train. Vui l√≤ng upload file training data tr∆∞·ªõc."
            )

        # 1. L·∫§Y 14 CH·ªà S·ªê
        indicators = {}

        if file:
            # Tr∆∞·ªùng h·ª£p 1: T·∫£i file XLSX m·ªõi
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng XLSX ho·∫∑c XLS")

            # L∆∞u file t·∫°m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # ƒê·ªçc file XLSX v√† t√≠nh 14 ch·ªâ s·ªë
                excel_processor.read_excel(tmp_file_path)
                indicators = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # Tr∆∞·ªùng h·ª£p 2: S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD
            indicators = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui l√≤ng cung c·∫•p file XLSX ho·∫∑c d·ªØ li·ªáu t·ª´ Tab D·ª± b√°o PD"
            )

        # 2. T√çNH ANOMALY SCORE
        anomaly_score = anomaly_system.calculate_anomaly_score(indicators)

        # 3. PH√ÅT HI·ªÜN C√ÅC FEATURES B·∫§T TH∆Ø·ªúNG
        abnormal_features = anomaly_system.detect_abnormal_features(indicators)

        # 4. PH√ÇN LO·∫†I LO·∫†I B·∫§T TH∆Ø·ªúNG
        anomaly_type = anomaly_system.classify_anomaly_type(indicators, abnormal_features)

        # 5. X√ÅC ƒê·ªäNH M·ª®C R·ª¶I RO
        if anomaly_score < 60:
            risk_level = "B√¨nh th∆∞·ªùng"
            risk_level_color = "#10B981"
            risk_level_icon = "‚ö†Ô∏è"
        elif anomaly_score < 80:
            risk_level = "B·∫•t th∆∞·ªùng Trung b√¨nh"
            risk_level_color = "#F59E0B"
            risk_level_icon = "üî∂"
        else:
            risk_level = "B·∫•t th∆∞·ªùng Cao"
            risk_level_color = "#EF4444"
            risk_level_icon = "üî¥"

        # 6. T·∫†O GI·∫¢I TH√çCH B·∫∞NG GEMINI AI
        gemini_explanation = anomaly_system.generate_gemini_explanation(
            indicators=indicators,
            anomaly_score=anomaly_score,
            abnormal_features=abnormal_features,
            anomaly_type=anomaly_type,
            gemini_api_key=GEMINI_API_KEY
        )

        # 7. SO S√ÅNH V·ªöI DN KH·ªéE M·∫†NH (cho Radar Chart)
        comparison_with_healthy = []
        for feature in anomaly_system.feature_names:
            comparison_with_healthy.append({
                'feature': anomaly_system.indicator_names[feature],
                'current': indicators[feature],
                'healthy_mean': anomaly_system.healthy_stats[feature]['mean']
            })

        # 8. TR·∫¢ V·ªÄ K·∫æT QU·∫¢
        return {
            "status": "success",
            "anomaly_score": anomaly_score,
            "risk_level": risk_level,
            "risk_level_color": risk_level_color,
            "risk_level_icon": risk_level_icon,
            "abnormal_features": abnormal_features,
            "anomaly_type": anomaly_type,
            "gemini_explanation": gemini_explanation,
            "comparison_with_healthy": comparison_with_healthy,
            "indicators": indicators
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi ki·ªÉm tra b·∫•t th∆∞·ªùng: {str(e)}")


# ================================================================================================
# MAIN
# ================================================================================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
