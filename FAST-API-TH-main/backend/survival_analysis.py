"""
Survival Analysis System for Credit Risk Assessment
Implements Cox Proportional Hazards, Random Survival Forest, and Kaplan-Meier Estimator
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

try:
    from lifelines import CoxPHFitter, KaplanMeierFitter
    from lifelines.utils import concordance_index
    LIFELINES_AVAILABLE = True
except ImportError:
    LIFELINES_AVAILABLE = False
    print("Warning: lifelines not installed. Install with: pip install lifelines")

try:
    from sksurv.ensemble import RandomSurvivalForest
    from sksurv.util import Surv
    SKSURV_AVAILABLE = True
except ImportError:
    SKSURV_AVAILABLE = False
    print("Warning: scikit-survival not installed. Install with: pip install scikit-survival")


class SurvivalAnalysisSystem:
    """
    H·ªá th·ªëng ph√¢n t√≠ch s·ªëng s√≥t cho ƒë√°nh gi√° r·ªßi ro t√≠n d·ª•ng
    D·ª± b√°o th·ªùi gian ƒë·∫øn khi doanh nghi·ªáp v·ª° n·ª£ (Time-to-Default)
    """

    def __init__(self):
        self.cox_model = None
        self.rsf_model = None
        self.km_fitter = None
        self.feature_names = [
            'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7',
            'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14'
        ]
        self.feature_name_mapping = {
            'X_1': 'Bi√™n l·ª£i nhu·∫≠n g·ªôp',
            'X_2': 'Bi√™n l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø',
            'X_3': 'ROA',
            'X_4': 'ROE',
            'X_5': 'H·ªá s·ªë n·ª£ tr√™n t√†i s·∫£n',
            'X_6': 'H·ªá s·ªë n·ª£ tr√™n VCSH',
            'X_7': 'Kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh',
            'X_8': 'Kh·∫£ nƒÉng thanh to√°n nhanh',
            'X_9': 'Kh·∫£ nƒÉng tr·∫£ l√£i',
            'X_10': 'Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc',
            'X_11': 'Kh·∫£ nƒÉng t·∫°o ti·ªÅn/VCSH',
            'X_12': 'V√≤ng quay h√†ng t·ªìn kho',
            'X_13': 'K·ª≥ thu ti·ªÅn b√¨nh qu√¢n',
            'X_14': 'Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n'
        }
        self.training_data = None
        self.metrics = {}

    def prepare_data(self, df: pd.DataFrame, duration_col: str = 'months_to_default',
                    event_col: str = 'event') -> Tuple[pd.DataFrame, np.ndarray, np.ndarray]:
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu cho survival analysis

        Args:
            df: DataFrame ch·ª©a 14 ch·ªâ s·ªë t√†i ch√≠nh + months_to_default + event
            duration_col: T√™n c·ªôt th·ªùi gian (th√°ng)
            event_col: T√™n c·ªôt event (1=v·ª° n·ª£, 0=censored)

        Returns:
            X: Features DataFrame
            durations: Array th·ªùi gian
            events: Array events
        """
        # L·∫•y 14 ch·ªâ s·ªë t√†i ch√≠nh
        X = df[self.feature_names].copy()

        # X·ª≠ l√Ω missing values
        X = X.fillna(X.median())

        # L·∫•y duration v√† event
        durations = df[duration_col].values
        events = df[event_col].values if event_col in df.columns else np.ones(len(df))

        # ƒê·∫£m b·∫£o duration > 0
        durations = np.maximum(durations, 0.1)

        return X, durations, events

    def train_cox_model(self, df: pd.DataFrame, duration_col: str = 'months_to_default',
                       event_col: str = 'event') -> Dict[str, Any]:
        """
        Hu·∫•n luy·ªán Cox Proportional Hazards Model

        Args:
            df: Training data v·ªõi 14 ch·ªâ s·ªë + months_to_default + event

        Returns:
            Dict ch·ª©a metrics v√† model info
        """
        if not LIFELINES_AVAILABLE:
            raise ImportError("lifelines package is required. Install with: pip install lifelines")

        # Chu·∫©n b·ªã d·ªØ li·ªáu
        X, durations, events = self.prepare_data(df, duration_col, event_col)

        # T·∫°o DataFrame cho Cox model
        cox_data = X.copy()
        cox_data['duration'] = durations
        cox_data['event'] = events

        # Hu·∫•n luy·ªán Cox model
        self.cox_model = CoxPHFitter(penalizer=0.01)
        self.cox_model.fit(cox_data, duration_col='duration', event_col='event')

        # T√≠nh C-index (concordance index)
        c_index = self.cox_model.concordance_index_

        # L∆∞u training data ƒë·ªÉ d√πng cho Kaplan-Meier baseline
        self.training_data = cox_data

        # L∆∞u metrics
        self.metrics['cox_c_index'] = float(c_index)
        self.metrics['cox_log_likelihood'] = float(self.cox_model.log_likelihood_)

        return {
            'model_type': 'Cox Proportional Hazards',
            'c_index': float(c_index),
            'log_likelihood': float(self.cox_model.log_likelihood_),
            'trained_at': datetime.now().isoformat(),
            'n_samples': len(df),
            'n_features': len(self.feature_names)
        }

    def train_random_survival_forest(self, df: pd.DataFrame,
                                     duration_col: str = 'months_to_default',
                                     event_col: str = 'event',
                                     n_estimators: int = 100) -> Dict[str, Any]:
        """
        Hu·∫•n luy·ªán Random Survival Forest

        Args:
            df: Training data
            n_estimators: S·ªë l∆∞·ª£ng trees

        Returns:
            Dict ch·ª©a metrics
        """
        if not SKSURV_AVAILABLE:
            raise ImportError("scikit-survival required. Install with: pip install scikit-survival")

        # Chu·∫©n b·ªã d·ªØ li·ªáu
        X, durations, events = self.prepare_data(df, duration_col, event_col)

        # T·∫°o structured array cho scikit-survival
        y = Surv.from_arrays(event=events.astype(bool), time=durations)

        # Hu·∫•n luy·ªán RSF
        self.rsf_model = RandomSurvivalForest(
            n_estimators=n_estimators,
            min_samples_split=10,
            min_samples_leaf=5,
            max_features="sqrt",
            n_jobs=-1,
            random_state=42
        )
        self.rsf_model.fit(X, y)

        # T√≠nh C-index
        c_index = self.rsf_model.score(X, y)

        # L∆∞u metrics
        self.metrics['rsf_c_index'] = float(c_index)
        self.metrics['rsf_n_estimators'] = n_estimators

        return {
            'model_type': 'Random Survival Forest',
            'c_index': float(c_index),
            'n_estimators': n_estimators,
            'trained_at': datetime.now().isoformat(),
            'n_samples': len(df),
            'n_features': len(self.feature_names)
        }

    def calculate_kaplan_meier(self, df: pd.DataFrame = None,
                              duration_col: str = 'months_to_default',
                              event_col: str = 'event') -> Dict[str, Any]:
        """
        T√≠nh Kaplan-Meier Estimator (baseline survival function)

        Args:
            df: Data (n·∫øu None, d√πng training data)

        Returns:
            Dict v·ªõi survival function v√† timeline
        """
        if not LIFELINES_AVAILABLE:
            raise ImportError("lifelines package required")

        # S·ª≠ d·ª•ng training data n·∫øu kh√¥ng c√≥ df
        if df is None:
            if self.training_data is None:
                raise ValueError("No training data available. Train Cox model first.")
            durations = self.training_data['duration'].values
            events = self.training_data['event'].values
        else:
            _, durations, events = self.prepare_data(df, duration_col, event_col)

        # Fit Kaplan-Meier
        self.km_fitter = KaplanMeierFitter()
        self.km_fitter.fit(durations, events)

        # L·∫•y survival function
        timeline = self.km_fitter.survival_function_.index.tolist()
        survival_probs = self.km_fitter.survival_function_['KM_estimate'].tolist()

        # T√≠nh median survival time
        median_survival = self.km_fitter.median_survival_time_

        return {
            'timeline': timeline,
            'survival_probabilities': survival_probs,
            'median_survival_time': float(median_survival) if not np.isnan(median_survival) else None,
            'event_count': int(events.sum()),
            'censored_count': int((1 - events).sum())
        }

    def predict_survival_curve(self, indicators: Dict[str, float],
                               model_type: str = 'cox',
                               timeline: Optional[List[float]] = None) -> Dict[str, Any]:
        """
        D·ª± b√°o survival curve cho m·ªôt doanh nghi·ªáp m·ªõi

        Args:
            indicators: Dict v·ªõi 14 ch·ªâ s·ªë t√†i ch√≠nh (X_1 ƒë·∫øn X_14)
            model_type: 'cox' ho·∫∑c 'rsf'
            timeline: List c√°c th·ªùi ƒëi·ªÉm (th√°ng) ƒë·ªÉ d·ª± b√°o

        Returns:
            Dict v·ªõi survival probabilities t·∫°i c√°c th·ªùi ƒëi·ªÉm
        """
        # T·∫°o DataFrame t·ª´ indicators
        X_new = pd.DataFrame([indicators])[self.feature_names]

        # X·ª≠ l√Ω missing values
        X_new = X_new.fillna(0)

        if model_type == 'cox':
            if self.cox_model is None:
                raise ValueError("Cox model not trained. Call train_cox_model() first.")

            # D·ª± b√°o survival function
            surv_func = self.cox_model.predict_survival_function(X_new)

            # N·∫øu kh√¥ng c√≥ timeline, d√πng timeline t·ª´ model
            if timeline is None:
                timeline = surv_func.index.tolist()

            # L·∫•y survival probabilities t·∫°i c√°c th·ªùi ƒëi·ªÉm
            survival_probs = [float(surv_func.iloc[0].loc[t]) if t in surv_func.index
                            else float(surv_func.iloc[0].iloc[np.searchsorted(surv_func.index, t)])
                            for t in timeline]

        elif model_type == 'rsf':
            if self.rsf_model is None:
                raise ValueError("RSF model not trained. Call train_random_survival_forest() first.")

            # D·ª± b√°o survival function
            surv_funcs = self.rsf_model.predict_survival_function(X_new, return_array=True)

            # Timeline t·ª´ RSF model
            if timeline is None:
                timeline = self.rsf_model.unique_times_.tolist()

            # L·∫•y survival probabilities
            survival_probs = [float(surv_funcs[0][np.searchsorted(self.rsf_model.unique_times_, t)])
                            for t in timeline]
        else:
            raise ValueError(f"Unknown model_type: {model_type}. Use 'cox' or 'rsf'.")

        return {
            'timeline': timeline,
            'survival_probabilities': survival_probs,
            'model_type': model_type
        }

    def calculate_median_time_to_default(self, indicators: Dict[str, float],
                                         model_type: str = 'cox') -> float:
        """
        T√≠nh median time-to-default cho m·ªôt doanh nghi·ªáp

        Args:
            indicators: Dict v·ªõi 14 ch·ªâ s·ªë
            model_type: 'cox' ho·∫∑c 'rsf'

        Returns:
            Median time (th√°ng)
        """
        # D·ª± b√°o survival curve
        result = self.predict_survival_curve(indicators, model_type)

        timeline = result['timeline']
        survival_probs = result['survival_probabilities']

        # T√¨m th·ªùi ƒëi·ªÉm m√† survival probability = 0.5
        for i, prob in enumerate(survival_probs):
            if prob <= 0.5:
                if i == 0:
                    return timeline[0]
                else:
                    # Linear interpolation
                    t1, p1 = timeline[i-1], survival_probs[i-1]
                    t2, p2 = timeline[i], survival_probs[i]
                    median_time = t1 + (0.5 - p1) * (t2 - t1) / (p2 - p1)
                    return float(median_time)

        # N·∫øu survival probability kh√¥ng bao gi·ªù xu·ªëng d∆∞·ªõi 0.5
        return float(timeline[-1])  # Return max time

    def get_hazard_ratios(self, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        L·∫•y hazard ratios t·ª´ Cox model (top K ch·ªâ s·ªë quan tr·ªçng nh·∫•t)

        Args:
            top_k: S·ªë l∆∞·ª£ng ch·ªâ s·ªë mu·ªën l·∫•y

        Returns:
            List c√°c dict v·ªõi feature name, hazard ratio, v√† p-value
        """
        if self.cox_model is None:
            raise ValueError("Cox model not trained. Call train_cox_model() first.")

        # L·∫•y hazard ratios v√† p-values
        hazard_ratios = np.exp(self.cox_model.params_)  # exp(coef) = hazard ratio
        p_values = self.cox_model.summary['p']
        confidence_intervals = self.cox_model.confidence_intervals_

        # T·∫°o list k·∫øt qu·∫£
        results = []
        for feature in self.feature_names:
            if feature in hazard_ratios.index:
                results.append({
                    'feature_code': feature,
                    'feature_name': self.feature_name_mapping[feature],
                    'hazard_ratio': float(hazard_ratios[feature]),
                    'coefficient': float(self.cox_model.params_[feature]),
                    'p_value': float(p_values[feature]),
                    'ci_lower': float(confidence_intervals.loc[feature].iloc[0]),
                    'ci_upper': float(confidence_intervals.loc[feature].iloc[1]),
                    'significance': 'C√≥ √Ω nghƒ©a' if p_values[feature] < 0.05 else 'Kh√¥ng c√≥ √Ω nghƒ©a'
                })

        # S·∫Øp x·∫øp theo absolute hazard ratio (c√†ng xa 1.0 c√†ng quan tr·ªçng)
        results.sort(key=lambda x: abs(np.log(x['hazard_ratio'])), reverse=True)

        return results[:top_k]

    def get_survival_probabilities_at_times(self, indicators: Dict[str, float],
                                           times: List[float] = [6, 12, 24],
                                           model_type: str = 'cox') -> Dict[float, float]:
        """
        T√≠nh survival probability t·∫°i c√°c th·ªùi ƒëi·ªÉm c·ª• th·ªÉ

        Args:
            indicators: Dict v·ªõi 14 ch·ªâ s·ªë
            times: List c√°c th·ªùi ƒëi·ªÉm (th√°ng)
            model_type: 'cox' ho·∫∑c 'rsf'

        Returns:
            Dict {time: survival_probability}
        """
        # D·ª± b√°o survival curve
        result = self.predict_survival_curve(indicators, model_type, timeline=None)

        timeline = np.array(result['timeline'])
        survival_probs = np.array(result['survival_probabilities'])

        # Interpolate ƒë·ªÉ l·∫•y survival prob t·∫°i c√°c th·ªùi ƒëi·ªÉm c·ª• th·ªÉ
        probs_at_times = {}
        for t in times:
            if t <= timeline[0]:
                probs_at_times[t] = float(survival_probs[0])
            elif t >= timeline[-1]:
                probs_at_times[t] = float(survival_probs[-1])
            else:
                # Linear interpolation
                idx = np.searchsorted(timeline, t)
                t1, p1 = timeline[idx-1], survival_probs[idx-1]
                t2, p2 = timeline[idx], survival_probs[idx]
                prob = p1 + (t - t1) * (p2 - p1) / (t2 - t1)
                probs_at_times[t] = float(prob)

        return probs_at_times

    def get_risk_classification(self, median_time: float) -> Dict[str, str]:
        """
        Ph√¢n lo·∫°i m·ª©c ƒë·ªô r·ªßi ro d·ª±a tr√™n median time-to-default

        Args:
            median_time: Median time (th√°ng)

        Returns:
            Dict v·ªõi risk level v√† color
        """
        if median_time < 6:
            return {
                'level': 'R·∫•t cao',
                'color': '#FFE8E8',
                'text_color': '#C62828',
                'icon': 'üî¥',
                'description': 'Nguy c∆° v·ª° n·ª£ c·ª±c k·ª≥ cao trong v√≤ng 6 th√°ng'
            }
        elif median_time < 12:
            return {
                'level': 'Cao',
                'color': '#FFE0CC',
                'text_color': '#E65100',
                'icon': 'üü†',
                'description': 'Nguy c∆° v·ª° n·ª£ cao trong v√≤ng 1 nƒÉm'
            }
        elif median_time < 24:
            return {
                'level': 'Trung b√¨nh',
                'color': '#FFF9E8',
                'text_color': '#F57C00',
                'icon': 'üü°',
                'description': 'C·∫ßn theo d√µi ch·∫∑t ch·∫Ω trong v√≤ng 2 nƒÉm'
            }
        elif median_time < 36:
            return {
                'level': 'Th·∫•p',
                'color': '#E8FFF0',
                'text_color': '#1B5E20',
                'icon': 'üü¢',
                'description': 'R·ªßi ro th·∫•p, t√¨nh tr·∫°ng t√†i ch√≠nh ·ªïn ƒë·ªãnh'
            }
        else:
            return {
                'level': 'R·∫•t th·∫•p',
                'color': '#C8F5DC',
                'text_color': '#0D5B2B',
                'icon': 'üü¢',
                'description': 'T√¨nh tr·∫°ng t√†i ch√≠nh r·∫•t t·ªët, r·ªßi ro r·∫•t th·∫•p'
            }

    def save_models(self, filepath: str = 'survival_models.pkl'):
        """L∆∞u models"""
        models = {
            'cox_model': self.cox_model,
            'rsf_model': self.rsf_model,
            'km_fitter': self.km_fitter,
            'training_data': self.training_data,
            'metrics': self.metrics
        }
        joblib.dump(models, filepath)
        return {'status': 'success', 'filepath': filepath}

    def load_models(self, filepath: str = 'survival_models.pkl'):
        """Load models"""
        models = joblib.load(filepath)
        self.cox_model = models['cox_model']
        self.rsf_model = models['rsf_model']
        self.km_fitter = models['km_fitter']
        self.training_data = models['training_data']
        self.metrics = models['metrics']
        return {'status': 'success', 'metrics': self.metrics}


# Singleton instance
survival_system = SurvivalAnalysisSystem()
